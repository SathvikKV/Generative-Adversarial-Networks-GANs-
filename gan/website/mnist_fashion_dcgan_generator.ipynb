{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d0da1d-12e6-4dbf-9652-4c7a0604f269",
   "metadata": {},
   "source": [
    "# DCGAN Implementation for MNIST and Fashion-MNIST\n",
    "\n",
    "This code implements a **Deep Convolutional Generative Adversarial Network (DCGAN)** to generate synthetic images for both the **MNIST (handwritten digits)** and **Fashion-MNIST (clothing items)** datasets. Let's break down what's happening in this implementation:\n",
    "\n",
    "---\n",
    "\n",
    "##  Data Preparation\n",
    "\n",
    "- Creates an output directory called `gan_outputs` to store generated images.\n",
    "- Loads both the MNIST and Fashion-MNIST datasets using TensorFlow's built-in functionality.\n",
    "- A preprocessing function:\n",
    "  - Normalizes pixel values to the range [-1, 1].\n",
    "  - Adds a channel dimension (needed for convolutional layers).\n",
    "- Class ID mapping:\n",
    "  - **Fashion-MNIST**: Focuses on 5 classes: `t-shirt`, `trouser`, `sandal`, `shirt`, `sneaker`.\n",
    "  - **MNIST**: Focuses on 5 digits: `0`, `1`, `2`, `3`, `7`.\n",
    "\n",
    "---\n",
    "\n",
    "##  GAN Architecture\n",
    "\n",
    "This implementation follows the standard **DCGAN** structure:\n",
    "\n",
    "###  Generator Network\n",
    "\n",
    "- **Input**: 100-dimensional noise vector.\n",
    "- **Layers**:\n",
    "  - Dense → reshape to (7×7×256)\n",
    "  - BatchNorm + LeakyReLU\n",
    "  - TransposedConv to (7×7×128)\n",
    "  - TransposedConv to (14×14×64)\n",
    "  - TransposedConv to (28×28×1)\n",
    "- **Output**: Uses `tanh` activation to match normalized [-1, 1] image values.\n",
    "\n",
    "###  Discriminator Network\n",
    "\n",
    "- **Input**: 28×28×1 image (real or generated)\n",
    "- **Layers**:\n",
    "  - Conv2D with strides → (14×14×64)\n",
    "  - Conv2D with strides → (7×7×128)\n",
    "  - LeakyReLU + Dropout (30%)\n",
    "  - Flatten + Dense → outputs real/fake probability\n",
    "\n",
    "---\n",
    "##  Loss Functions and Training\n",
    "\n",
    "- **Loss Function**: Binary cross-entropy\n",
    "  - Discriminator: classify real images as `1`, fake as `0`\n",
    "  - Generator: tries to trick discriminator (fake as `1`)\n",
    "- **Optimizer**: Adam (learning rate = 1e-4)\n",
    "- **Training Loop**:\n",
    "  - Custom training loop with `tf.GradientTape`\n",
    "  - Decorated with `@tf.function` for performance\n",
    "\n",
    "---\n",
    "\n",
    "##  Image Generation Process\n",
    "\n",
    "- **Separate GANs** are trained for each selected class in MNIST and Fashion-MNIST.\n",
    "\n",
    "### For Each Class:\n",
    "\n",
    "1. Select up to 1,000 training examples of that class.\n",
    "2. Save one **real** example for reference.\n",
    "3. Train a class-specific GAN for **1,000 epochs**.\n",
    "4. Generate **9 synthetic images**:\n",
    "   - One saved as `gan_dataset_class.png`\n",
    "   - Eight saved as `aug_dataset_class_N.png`\n",
    "\n",
    "---\n",
    "\n",
    "## Key Technical Aspects\n",
    "\n",
    "###  Class-Conditional Generation\n",
    "- Trains a **separate GAN for each class**, which helps improve generation quality.\n",
    "\n",
    "###  Architecture Choices\n",
    "- Follows DCGAN best practices:\n",
    "  - **Strided convolutions** instead of pooling.\n",
    "  - **Batch normalization** in both networks (except outputs).\n",
    "  - **LeakyReLU** for stable training.\n",
    "  - **No hidden dense layers** in the middle.\n",
    "\n",
    "###  Visualization\n",
    "- Automatically saves **real** and **generated** samples to help assess performance.\n",
    "\n",
    "---\n",
    "\n",
    "##  Why This Matters\n",
    "\n",
    "This implementation demonstrates how **GANs** can be used for **data augmentation**:\n",
    "\n",
    "- Generates new, realistic samples for each class.\n",
    "- Can be useful in training more robust classifiers.\n",
    "- Preserves distributional properties of real data while introducing novel variations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9c1cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\sathu\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DCGAN for fashion class: tshirt\n",
      "Epoch 0: Gen Loss = 0.6530, Disc Loss = 1.3437\n",
      "Epoch 100: Gen Loss = 0.7959, Disc Loss = 1.3327\n",
      "Epoch 200: Gen Loss = 0.6535, Disc Loss = 1.3906\n",
      "Epoch 300: Gen Loss = 0.6940, Disc Loss = 1.4324\n",
      "Epoch 400: Gen Loss = 0.7208, Disc Loss = 1.3440\n",
      "Epoch 500: Gen Loss = 0.7477, Disc Loss = 1.5819\n",
      "Epoch 600: Gen Loss = 0.9946, Disc Loss = 1.1122\n",
      "Epoch 700: Gen Loss = 0.7924, Disc Loss = 1.3116\n",
      "Epoch 800: Gen Loss = 1.2244, Disc Loss = 0.9063\n",
      "Epoch 900: Gen Loss = 0.9347, Disc Loss = 1.1511\n",
      "Epoch 999: Gen Loss = 0.9900, Disc Loss = 1.0188\n",
      "Training DCGAN for fashion class: trouser\n",
      "Epoch 0: Gen Loss = 0.5961, Disc Loss = 1.2615\n",
      "Epoch 100: Gen Loss = 0.6993, Disc Loss = 1.4320\n",
      "Epoch 200: Gen Loss = 0.7269, Disc Loss = 1.3393\n",
      "Epoch 300: Gen Loss = 0.7089, Disc Loss = 1.4335\n",
      "Epoch 400: Gen Loss = 0.6766, Disc Loss = 1.4937\n",
      "Epoch 500: Gen Loss = 0.7345, Disc Loss = 1.4377\n",
      "Epoch 600: Gen Loss = 0.7330, Disc Loss = 1.4266\n",
      "Epoch 700: Gen Loss = 0.9141, Disc Loss = 1.1556\n",
      "Epoch 800: Gen Loss = 0.9226, Disc Loss = 1.2124\n",
      "Epoch 900: Gen Loss = 0.7646, Disc Loss = 1.4570\n",
      "Epoch 999: Gen Loss = 0.9053, Disc Loss = 1.2839\n",
      "Training DCGAN for fashion class: sandal\n",
      "Epoch 0: Gen Loss = 0.6358, Disc Loss = 1.2669\n",
      "Epoch 100: Gen Loss = 0.6939, Disc Loss = 1.4458\n",
      "Epoch 200: Gen Loss = 0.5636, Disc Loss = 1.5753\n",
      "Epoch 300: Gen Loss = 0.6612, Disc Loss = 1.4364\n",
      "Epoch 400: Gen Loss = 0.8090, Disc Loss = 1.2632\n",
      "Epoch 500: Gen Loss = 0.8141, Disc Loss = 1.2611\n",
      "Epoch 600: Gen Loss = 0.9899, Disc Loss = 1.1374\n",
      "Epoch 700: Gen Loss = 0.7133, Disc Loss = 1.4284\n",
      "Epoch 800: Gen Loss = 0.8543, Disc Loss = 1.2447\n",
      "Epoch 900: Gen Loss = 0.9674, Disc Loss = 1.0947\n",
      "Epoch 999: Gen Loss = 0.9017, Disc Loss = 1.2713\n",
      "Training DCGAN for fashion class: shirt\n",
      "Epoch 0: Gen Loss = 0.6479, Disc Loss = 1.3024\n",
      "Epoch 100: Gen Loss = 1.0315, Disc Loss = 0.9251\n",
      "Epoch 200: Gen Loss = 0.8008, Disc Loss = 1.3901\n",
      "Epoch 300: Gen Loss = 0.7907, Disc Loss = 1.2823\n",
      "Epoch 400: Gen Loss = 0.7428, Disc Loss = 1.4576\n",
      "Epoch 500: Gen Loss = 0.9453, Disc Loss = 1.2831\n",
      "Epoch 600: Gen Loss = 0.9471, Disc Loss = 1.1187\n",
      "Epoch 700: Gen Loss = 1.0493, Disc Loss = 1.1625\n",
      "Epoch 800: Gen Loss = 0.7502, Disc Loss = 1.3396\n",
      "Epoch 900: Gen Loss = 0.8780, Disc Loss = 1.1696\n",
      "Epoch 999: Gen Loss = 0.7881, Disc Loss = 1.3062\n",
      "Training DCGAN for fashion class: sneaker\n",
      "Epoch 0: Gen Loss = 0.6332, Disc Loss = 1.2619\n",
      "Epoch 100: Gen Loss = 0.6428, Disc Loss = 1.5338\n",
      "Epoch 200: Gen Loss = 0.6740, Disc Loss = 1.4437\n",
      "Epoch 300: Gen Loss = 0.6713, Disc Loss = 1.3982\n",
      "Epoch 400: Gen Loss = 0.8856, Disc Loss = 1.2272\n",
      "Epoch 500: Gen Loss = 0.7429, Disc Loss = 1.4265\n",
      "Epoch 600: Gen Loss = 0.8468, Disc Loss = 1.2242\n",
      "Epoch 700: Gen Loss = 0.8089, Disc Loss = 1.3021\n",
      "Epoch 800: Gen Loss = 0.9234, Disc Loss = 1.1276\n",
      "Epoch 900: Gen Loss = 0.6352, Disc Loss = 1.6088\n",
      "Epoch 999: Gen Loss = 0.8602, Disc Loss = 1.1971\n",
      "Training DCGAN for mnist class: 0\n",
      "Epoch 0: Gen Loss = 0.6562, Disc Loss = 1.3119\n",
      "Epoch 100: Gen Loss = 0.7598, Disc Loss = 1.1843\n",
      "Epoch 200: Gen Loss = 0.6871, Disc Loss = 1.4567\n",
      "Epoch 300: Gen Loss = 0.6788, Disc Loss = 1.4079\n",
      "Epoch 400: Gen Loss = 0.6754, Disc Loss = 1.4518\n",
      "Epoch 500: Gen Loss = 0.8997, Disc Loss = 1.1420\n",
      "Epoch 600: Gen Loss = 0.7222, Disc Loss = 1.4673\n",
      "Epoch 700: Gen Loss = 0.8297, Disc Loss = 1.1516\n",
      "Epoch 800: Gen Loss = 0.7334, Disc Loss = 1.4318\n",
      "Epoch 900: Gen Loss = 0.8240, Disc Loss = 1.2093\n",
      "Epoch 999: Gen Loss = 0.8850, Disc Loss = 1.1170\n",
      "Training DCGAN for mnist class: 1\n",
      "Epoch 0: Gen Loss = 0.6206, Disc Loss = 1.2641\n",
      "Epoch 100: Gen Loss = 0.7365, Disc Loss = 1.3447\n",
      "Epoch 200: Gen Loss = 0.7193, Disc Loss = 1.3599\n",
      "Epoch 300: Gen Loss = 0.7059, Disc Loss = 1.3805\n",
      "Epoch 400: Gen Loss = 0.6685, Disc Loss = 1.4486\n",
      "Epoch 500: Gen Loss = 0.7113, Disc Loss = 1.3589\n",
      "Epoch 600: Gen Loss = 0.7329, Disc Loss = 1.3511\n",
      "Epoch 700: Gen Loss = 0.7257, Disc Loss = 1.3638\n",
      "Epoch 800: Gen Loss = 0.7026, Disc Loss = 1.4011\n",
      "Epoch 900: Gen Loss = 0.6947, Disc Loss = 1.4015\n",
      "Epoch 999: Gen Loss = 0.6838, Disc Loss = 1.4408\n",
      "Training DCGAN for mnist class: 2\n",
      "Epoch 0: Gen Loss = 0.6592, Disc Loss = 1.3123\n",
      "Epoch 100: Gen Loss = 0.7652, Disc Loss = 1.2898\n",
      "Epoch 200: Gen Loss = 0.7483, Disc Loss = 1.3826\n",
      "Epoch 300: Gen Loss = 0.7666, Disc Loss = 1.3418\n",
      "Epoch 400: Gen Loss = 0.8316, Disc Loss = 1.2567\n",
      "Epoch 500: Gen Loss = 0.8342, Disc Loss = 1.2361\n",
      "Epoch 600: Gen Loss = 0.7854, Disc Loss = 1.3220\n",
      "Epoch 700: Gen Loss = 0.7054, Disc Loss = 1.4186\n",
      "Epoch 800: Gen Loss = 0.8612, Disc Loss = 1.2107\n",
      "Epoch 900: Gen Loss = 0.8466, Disc Loss = 1.2581\n",
      "Epoch 999: Gen Loss = 0.8616, Disc Loss = 1.1922\n",
      "Training DCGAN for mnist class: 3\n",
      "Epoch 0: Gen Loss = 0.6414, Disc Loss = 1.2440\n",
      "Epoch 100: Gen Loss = 0.6972, Disc Loss = 1.3876\n",
      "Epoch 200: Gen Loss = 0.7196, Disc Loss = 1.3070\n",
      "Epoch 300: Gen Loss = 0.7500, Disc Loss = 1.2705\n",
      "Epoch 400: Gen Loss = 0.7163, Disc Loss = 1.3502\n",
      "Epoch 500: Gen Loss = 0.7507, Disc Loss = 1.3181\n",
      "Epoch 600: Gen Loss = 0.8564, Disc Loss = 1.3369\n",
      "Epoch 700: Gen Loss = 0.7147, Disc Loss = 1.4808\n",
      "Epoch 800: Gen Loss = 0.7703, Disc Loss = 1.3455\n",
      "Epoch 900: Gen Loss = 0.7567, Disc Loss = 1.2745\n",
      "Epoch 999: Gen Loss = 0.7329, Disc Loss = 1.5690\n",
      "Training DCGAN for mnist class: 7\n",
      "Epoch 0: Gen Loss = 0.6219, Disc Loss = 1.2885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 135\u001b[0m\n\u001b[0;32m    133\u001b[0m     real_sample \u001b[38;5;241m=\u001b[39m (samples[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m127.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m127.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m    134\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimsave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/real_mnist_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, real_sample, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 135\u001b[0m     train_dcgan(samples, label, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone generating real and GAN-based images.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 107\u001b[0m, in \u001b[0;36mtrain_dcgan\u001b[1;34m(data, label_name, dataset_name, epochs, batch_size)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m--> 107\u001b[0m         g_loss, d_loss \u001b[38;5;241m=\u001b[39m train_step(image_batch)\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Gen Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg_loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Disc Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    870\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    871\u001b[0m   )\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1689\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1690\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1691\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1692\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1693\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1694\u001b[0m   )\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# DCGAN Trainer for FashionMNIST and MNIST (Class-Specific Samples)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "# Create output folder\n",
    "output_dir = \"gan_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load datasets\n",
    "(fashion_x_train, fashion_y_train), _ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(mnist_x_train, mnist_y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize and reshape\n",
    "def preprocess(x):\n",
    "    x = (x.astype('float32') - 127.5) / 127.5\n",
    "    return np.expand_dims(x, axis=-1)\n",
    "\n",
    "fashion_x_train = preprocess(fashion_x_train)\n",
    "mnist_x_train = preprocess(mnist_x_train)\n",
    "\n",
    "# Class labels to generate\n",
    "fashion_labels = {\n",
    "    0: 'tshirt',\n",
    "    1: 'trouser',\n",
    "    5: 'sandal',\n",
    "    6: 'shirt',\n",
    "    7: 'sneaker'\n",
    "}\n",
    "\n",
    "mnist_labels = {\n",
    "    0: '0',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    7: '7'\n",
    "}\n",
    "\n",
    "# DCGAN Components\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Reshape((7, 7, 256)),\n",
    "        layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    return cross_entropy(tf.ones_like(real_output), real_output) + cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Training loop\n",
    "def train_dcgan(data, label_name, dataset_name, epochs=1000, batch_size=256):\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(10000).batch(batch_size)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(images):\n",
    "        noise = tf.random.normal([batch_size, 100])\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = generator(noise, training=True)\n",
    "            real_output = discriminator(images, training=True)\n",
    "            fake_output = discriminator(generated_images, training=True)\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "        return gen_loss, disc_loss\n",
    "\n",
    "    print(f\"Training DCGAN for {dataset_name} class: {label_name}\")\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            g_loss, d_loss = train_step(image_batch)\n",
    "        if epoch % 100 == 0 or epoch == epochs - 1:\n",
    "            print(f\"Epoch {epoch}: Gen Loss = {g_loss.numpy():.4f}, Disc Loss = {d_loss.numpy():.4f}\")\n",
    "\n",
    "    # Save images\n",
    "    noise = tf.random.normal([9, 100])\n",
    "    generated_images = generator(noise, training=False).numpy()\n",
    "    for i, img in enumerate(generated_images):\n",
    "        img = (img * 127.5 + 127.5).astype('uint8').squeeze()\n",
    "        fname = f\"gan_{dataset_name}_{label_name}.png\" if i == 0 else f\"aug_{dataset_name}_{label_name}_{i}.png\"\n",
    "        plt.imsave(os.path.join(output_dir, fname), img, cmap='gray')\n",
    "\n",
    "# Generate for FashionMNIST\n",
    "for class_id in fashion_labels:\n",
    "    label = fashion_labels[class_id]\n",
    "    idx = np.where(fashion_y_train == class_id)[0][:1000]\n",
    "    samples = fashion_x_train[idx]\n",
    "    real_sample = (samples[0] * 127.5 + 127.5).astype('uint8').squeeze()\n",
    "    plt.imsave(f\"{output_dir}/real_fashion_{label}.png\", real_sample, cmap='gray')\n",
    "    train_dcgan(samples, label, \"fashion\")\n",
    "\n",
    "# Generate for MNIST\n",
    "for class_id in mnist_labels:\n",
    "    label = mnist_labels[class_id]\n",
    "    idx = np.where(mnist_y_train == class_id)[0][:1000]\n",
    "    samples = mnist_x_train[idx]\n",
    "    real_sample = (samples[0] * 127.5 + 127.5).astype('uint8').squeeze()\n",
    "    plt.imsave(f\"{output_dir}/real_mnist_{label}.png\", real_sample, cmap='gray')\n",
    "    train_dcgan(samples, label, \"mnist\")\n",
    "\n",
    "print(\"Done generating real and GAN-based images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95261f60-ba93-4f0e-ac49-b1fa1b862eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90b008-5762-4304-9eb9-f664a14e16af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
